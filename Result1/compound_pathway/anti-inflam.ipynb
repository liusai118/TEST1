{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30322c87-bf85-48be-b512-2e3bcc8be832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f87fc4-db34-4852-a6b2-2c6158abb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgan saved in res_morgan_fingerprint.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "radius = 2              \n",
    "n_bits = 2048          \n",
    "\n",
    "df = pd.read_csv(\"anti_inflam.csv\")\n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "\n",
    "morgan_data = []\n",
    "invalid_smiles = []\n",
    "\n",
    "for smiles in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        invalid_smiles.append(smiles)\n",
    "        continue\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    bit_arr = [int(x) for x in fp]\n",
    "    morgan_data.append([smiles] + bit_arr)\n",
    "\n",
    "\n",
    "columns = [\"SMILES\"] + [f\"bit_{i}\" for i in range(n_bits)]\n",
    "\n",
    "\n",
    "morgan_df = pd.DataFrame(morgan_data, columns=columns)\n",
    "morgan_df.to_csv(\"res_morgan_fingerprint1.csv\", index=False)\n",
    "print(\"Morgan saved in res_morgan_fingerprint.csv\")\n",
    "\n",
    "if invalid_smiles:\n",
    "    print(\"problem：\")\n",
    "    for s in invalid_smiles:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efe5a2b-3538-453e-8691-6c70677fb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"newtest.csv\")\n",
    "smiles_list2 = df2[\"SMILES\"].tolist()\n",
    "morgan_data2 = []\n",
    "invalid_smiles = []\n",
    "for smiles in smiles_list2:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        invalid_smiles.append(smiles)\n",
    "        continue\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    bit_arr = [int(x) for x in fp]\n",
    "    morgan_data2.append([smiles] + bit_arr)\n",
    "columns = [\"SMILES\"] + [f\"bit_{i}\" for i in range(n_bits)]\n",
    "morgan_df2 = pd.DataFrame(morgan_data2, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27881782-5558-4d26-a3fc-73e2f8fe4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df, morgan_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec22bca-159c-4314-963f-a33a75a0d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ...\n",
      "   best: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      " ...\n",
      "   best: {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "\n",
      " ...\n",
      "   best: {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      " ...\n",
      "   best: {'colsample_bytree': 0.8417669517111269, 'gamma': 0.26992054565083656, 'learning_rate': 0.050612244946953884, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.7159005811655073}\n",
      "\n",
      " ...\n",
      "   best: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "\n",
      ":\n",
      "\n",
      "{'DecisionTree': {'max_depth': 10,\n",
      "                  'min_samples_leaf': 1,\n",
      "                  'min_samples_split': 2},\n",
      " 'GradientBoosting': {'learning_rate': 0.1,\n",
      "                      'max_depth': 3,\n",
      "                      'n_estimators': 200,\n",
      "                      'subsample': 1.0},\n",
      " 'LogisticRegression': {'C': 0.1, 'penalty': 'l2'},\n",
      " 'RandomForest': {'max_depth': None,\n",
      "                  'max_features': 'sqrt',\n",
      "                  'min_samples_split': 2,\n",
      "                  'n_estimators': 200},\n",
      " 'XGBoost': {'colsample_bytree': 0.8417669517111269,\n",
      "             'gamma': 0.26992054565083656,\n",
      "             'learning_rate': 0.050612244946953884,\n",
      "             'max_depth': 7,\n",
      "             'n_estimators': 200,\n",
      "             'subsample': 0.7159005811655073}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 2]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, stratify=label, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search_spaces = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 3, 5]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"max_features\": [\"auto\", \"sqrt\"]\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear'),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": randint(3, 10),\n",
    "            \"learning_rate\": uniform(0.01, 0.2),\n",
    "            \"subsample\": uniform(0.6, 0.4),\n",
    "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
    "            \"gamma\": uniform(0, 0.5)\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"subsample\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "best_params = {} \n",
    "\n",
    "for name, config in search_spaces.items():\n",
    "    print(f\"\\n ...\")\n",
    "    if config[\"method\"] == \"grid\":\n",
    "        searcher = GridSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        searcher = RandomizedSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_distributions=config[\"params\"],\n",
    "            n_iter=30,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    searcher.fit(X_train, y_train)\n",
    "    best_model = searcher.best_estimator_\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": searcher.best_params_,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "    best_params[name] = searcher.best_params_\n",
    "\n",
    "\n",
    "    print(f\"   best: {searcher.best_params_}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "save_dir = \"stat3\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "results_df.to_csv(\"stat3/model_best_params_auc.csv\", index=False,)\n",
    "\n",
    "print(\"\\n:\\n\")\n",
    "import pprint\n",
    "pprint.pprint(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bfac0-0a6b-4450-a81b-df334480c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree  AUC: 0.78\n",
      "RandomForest  AUC: 0.93\n",
      "LogisticRegression  AUC: 0.95\n",
      "XGBoost  AUC: 0.94\n",
      "GradientBoosting  AUC: 0.93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 2]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "\n",
    "\n",
    "binary_classes = sorted(label.unique())\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, stratify=label, random_state=42)\n",
    "\n",
    "\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42).set_params(**best_params[\"DecisionTree\"]),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42).set_params(**best_params[\"RandomForest\"]),\n",
    "    'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=200, random_state=42).set_params(**best_params[\"LogisticRegression\"]),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False, eval_metric='logloss').set_params(**best_params[\"XGBoost\"]),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42).set_params(**best_params[\"GradientBoosting\"])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    })\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=binary_classes, yticklabels=binary_classes)\n",
    "    plt.title(f'{model_name} 混淆矩阵')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.svg', format='svg')\n",
    "    plt.close()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', lw=2)\n",
    "\n",
    "    return auc\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc = evaluate_model(model, model_name)\n",
    "    print(f\"{model_name}  AUC: {auc:.2f}\")\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', lw=1)\n",
    "plt.title('ROC曲线', fontsize=16)\n",
    "plt.xlabel('假阳性率', fontsize=12)\n",
    "plt.ylabel('真阳性率', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.savefig('stat3/combined_roc_curves.svg', format='svg')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('stat3/model_evaluation_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbdf5554-68a1-41f8-bcf3-27e1427fa1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>bit_0</th>\n",
       "      <th>bit_1</th>\n",
       "      <th>bit_2</th>\n",
       "      <th>bit_3</th>\n",
       "      <th>bit_4</th>\n",
       "      <th>bit_5</th>\n",
       "      <th>bit_6</th>\n",
       "      <th>bit_7</th>\n",
       "      <th>bit_8</th>\n",
       "      <th>...</th>\n",
       "      <th>bit_2038</th>\n",
       "      <th>bit_2039</th>\n",
       "      <th>bit_2040</th>\n",
       "      <th>bit_2041</th>\n",
       "      <th>bit_2042</th>\n",
       "      <th>bit_2043</th>\n",
       "      <th>bit_2044</th>\n",
       "      <th>bit_2045</th>\n",
       "      <th>bit_2046</th>\n",
       "      <th>bit_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1=CC(=CC(=C1)[C@@H]2CCCN2CC3=CC=C(C=C3)OC4=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCCCC1=CC(=C(C(=C1)O)[C@@H]2C=C(CC[C@H]2C(=C)...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C[C@@H]1CC[C@H](C2=C(CC[C@H]12)C)/C=C(\\C)/C(=O)O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)NC1=CC(=CC=C1)N2CCN(CC2)CCCCNS(=O)(=O)CC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1(C2CCC1([C@H](C2)OC(=O)N[C@@](C)(CC3=CNC4=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>C(CCN=C(N)N)CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>CN[C@H]1CC[C@H](C2=CC=CC=C12)C3=CC(=C(C=C3)Cl)Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>C1(C(C(C(C(C1O)O)O)O)O)O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>CC(CC1C2=CC=CC=C2CCC3=CC=CC=C13)CN(C)C.Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>CC(CC1C2=CC=CC=C2CCC3=CC=CC=C13)CN(C)C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES  bit_0  bit_1  bit_2  \\\n",
       "0    CC1=CC(=CC(=C1)[C@@H]2CCCN2CC3=CC=C(C=C3)OC4=C...      0      0      0   \n",
       "1    CCCCCC1=CC(=C(C(=C1)O)[C@@H]2C=C(CC[C@H]2C(=C)...      0      0      0   \n",
       "2     C[C@@H]1CC[C@H](C2=C(CC[C@H]12)C)/C=C(\\C)/C(=O)O      0      0      0   \n",
       "3    CC(=O)NC1=CC(=CC=C1)N2CCN(CC2)CCCCNS(=O)(=O)CC...      0      0      1   \n",
       "4    CC1(C2CCC1([C@H](C2)OC(=O)N[C@@](C)(CC3=CNC4=C...      0      1      0   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "250                                     C(CCN=C(N)N)CN      0      0      0   \n",
       "251   CN[C@H]1CC[C@H](C2=CC=CC=C12)C3=CC(=C(C=C3)Cl)Cl      0      0      0   \n",
       "252                           C1(C(C(C(C(C1O)O)O)O)O)O      0      0      0   \n",
       "253          CC(CC1C2=CC=CC=C2CCC3=CC=CC=C13)CN(C)C.Cl      0      1      0   \n",
       "254             CC(CC1C2=CC=CC=C2CCC3=CC=CC=C13)CN(C)C      0      1      0   \n",
       "\n",
       "     bit_3  bit_4  bit_5  bit_6  bit_7  bit_8  ...  bit_2038  bit_2039  \\\n",
       "0        0      0      0      0      0      0  ...         0         0   \n",
       "1        0      0      0      0      0      0  ...         0         0   \n",
       "2        0      0      0      0      0      0  ...         0         0   \n",
       "3        0      0      0      0      0      0  ...         0         0   \n",
       "4        0      0      0      0      0      0  ...         0         0   \n",
       "..     ...    ...    ...    ...    ...    ...  ...       ...       ...   \n",
       "250      0      0      0      0      0      0  ...         0         0   \n",
       "251      0      0      0      0      0      0  ...         0         0   \n",
       "252      0      0      0      0      0      0  ...         0         0   \n",
       "253      0      0      0      0      0      0  ...         0         0   \n",
       "254      0      0      0      0      0      0  ...         0         0   \n",
       "\n",
       "     bit_2040  bit_2041  bit_2042  bit_2043  bit_2044  bit_2045  bit_2046  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "250         0         0         0         0         0         0         0   \n",
       "251         0         0         0         0         0         0         0   \n",
       "252         0         0         0         0         0         0         0   \n",
       "253         0         0         0         0         0         0         0   \n",
       "254         0         0         0         0         0         0         0   \n",
       "\n",
       "     bit_2047  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "..        ...  \n",
       "250         0  \n",
       "251         0  \n",
       "252         0  \n",
       "253         0  \n",
       "254         0  \n",
       "\n",
       "[255 rows x 2049 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morgan_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8ec1b-8371-453c-b505-c206229b87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = morgan_df2.iloc[:, 1:]\n",
    "rf_model = models[\"LogisticRegression\"] \n",
    "pred_labels = rf_model.predict(new_features)\n",
    "pred_probs = rf_model.predict_proba(new_features)[:, 1]\n",
    "\n",
    "df2[\"Predicted_Label\"] = pred_labels\n",
    "df2[\"Predicted_Probability\"] = pred_probs\n",
    "df2.to_csv(\"stat3/prediction_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe0fba0-32a1-4e20-b9f6-6a4311a770ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ...\n",
      "   best: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\n",
      " ...\n",
      "   best: {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "\n",
      " ...\n",
      "   best: {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      " ...\n",
      "   best: {'colsample_bytree': 0.8123738333268545, 'gamma': 0.22389158228654582, 'learning_rate': 0.12057861781426558, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.9046478461314871}\n",
      "\n",
      " ...\n",
      "   best: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "\n",
      ":\n",
      "\n",
      "{'DecisionTree': {'max_depth': 10,\n",
      "                  'min_samples_leaf': 5,\n",
      "                  'min_samples_split': 2},\n",
      " 'GradientBoosting': {'learning_rate': 0.1,\n",
      "                      'max_depth': 5,\n",
      "                      'n_estimators': 200,\n",
      "                      'subsample': 1.0},\n",
      " 'LogisticRegression': {'C': 0.1, 'penalty': 'l2'},\n",
      " 'RandomForest': {'max_depth': None,\n",
      "                  'max_features': 'sqrt',\n",
      "                  'min_samples_split': 2,\n",
      "                  'n_estimators': 200},\n",
      " 'XGBoost': {'colsample_bytree': 0.8123738333268545,\n",
      "             'gamma': 0.22389158228654582,\n",
      "             'learning_rate': 0.12057861781426558,\n",
      "             'max_depth': 9,\n",
      "             'n_estimators': 200,\n",
      "             'subsample': 0.9046478461314871}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 3]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, stratify=label, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search_spaces = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 3, 5]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"max_features\": [\"auto\", \"sqrt\"]\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear'),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": randint(3, 10),\n",
    "            \"learning_rate\": uniform(0.01, 0.2),\n",
    "            \"subsample\": uniform(0.6, 0.4),\n",
    "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
    "            \"gamma\": uniform(0, 0.5)\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"subsample\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "best_params = {} \n",
    "\n",
    "for name, config in search_spaces.items():\n",
    "    print(f\"\\n ...\")\n",
    "    if config[\"method\"] == \"grid\":\n",
    "        searcher = GridSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        searcher = RandomizedSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_distributions=config[\"params\"],\n",
    "            n_iter=30,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    searcher.fit(X_train, y_train)\n",
    "    best_model = searcher.best_estimator_\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": searcher.best_params_,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "    best_params[name] = searcher.best_params_\n",
    "\n",
    "\n",
    "    print(f\"   best: {searcher.best_params_}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "save_dir = \"mtor\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "results_df.to_csv(\"mtor/model_best_params_auc.csv\", index=False,)\n",
    "\n",
    "print(\"\\n:\\n\")\n",
    "import pprint\n",
    "pprint.pprint(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e4de56-8956-479a-80b9-a22d36c3b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree  AUC: 0.77\n",
      "RandomForest  AUC: 0.89\n",
      "LogisticRegression  AUC: 0.87\n",
      "XGBoost  AUC: 0.89\n",
      "GradientBoosting  AUC: 0.88\n"
     ]
    }
   ],
   "source": [
    "label = merged_df.iloc[:, 3]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "binary_classes = sorted(label.unique())\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, stratify=label, random_state=42)\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42).set_params(**best_params[\"DecisionTree\"]),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42).set_params(**best_params[\"RandomForest\"]),\n",
    "    'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=200, random_state=42).set_params(**best_params[\"LogisticRegression\"]),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False, eval_metric='logloss').set_params(**best_params[\"XGBoost\"]),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42).set_params(**best_params[\"GradientBoosting\"])\n",
    "}\n",
    "results = []\n",
    "plt.figure(figsize=(10, 8))\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    })\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=binary_classes, yticklabels=binary_classes)\n",
    "    plt.title(f'{model_name} 混淆矩阵')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.svg', format='svg')\n",
    "    plt.close()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', lw=2)\n",
    "    return auc\n",
    "for model_name, model in models.items():\n",
    "    auc = evaluate_model(model, model_name)\n",
    "    print(f\"{model_name}  AUC: {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', lw=1)\n",
    "plt.title('ROC曲线', fontsize=16)\n",
    "plt.xlabel('假阳性率', fontsize=12)\n",
    "plt.ylabel('真阳性率', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.savefig('mtor/combined_roc_curves.svg', format='svg')\n",
    "plt.close()\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('mtor/model_evaluation_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1d290-32b9-44c3-8ec0-2db3d091aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = morgan_df2.iloc[:, 1:]\n",
    "rf_model = models[\"XGBoost\"] \n",
    "pred_labels = rf_model.predict(new_features)\n",
    "pred_probs = rf_model.predict_proba(new_features)[:, 1]\n",
    "\n",
    "df2[\"Predicted_Label\"] = pred_labels\n",
    "df2[\"Predicted_Probability\"] = pred_probs\n",
    "df2.to_csv(\"mtor/prediction_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b817ab69-383d-4fe5-94eb-5e347dd6832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ...\n",
      "   best: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\n",
      " ...\n",
      "   best: {'n_estimators': 200, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': None}\n",
      "\n",
      " ...\n",
      "   best: {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      " ...\n",
      "   best: {'colsample_bytree': 0.7243929286862649, 'gamma': 0.16259166101337352, 'learning_rate': 0.15592123566761282, 'max_depth': 8, 'n_estimators': 200, 'subsample': 0.8244973703390804}\n",
      "\n",
      " ...\n",
      "   best: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "\n",
      ":\n",
      "\n",
      "{'DecisionTree': {'max_depth': 10,\n",
      "                  'min_samples_leaf': 5,\n",
      "                  'min_samples_split': 2},\n",
      " 'GradientBoosting': {'learning_rate': 0.1,\n",
      "                      'max_depth': 5,\n",
      "                      'n_estimators': 200,\n",
      "                      'subsample': 1.0},\n",
      " 'LogisticRegression': {'C': 0.1, 'penalty': 'l2'},\n",
      " 'RandomForest': {'max_depth': None,\n",
      "                  'max_features': 'sqrt',\n",
      "                  'min_samples_split': 5,\n",
      "                  'n_estimators': 200},\n",
      " 'XGBoost': {'colsample_bytree': 0.7243929286862649,\n",
      "             'gamma': 0.16259166101337352,\n",
      "             'learning_rate': 0.15592123566761282,\n",
      "             'max_depth': 8,\n",
      "             'n_estimators': 200,\n",
      "             'subsample': 0.8244973703390804}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 4]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, stratify=label, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search_spaces = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 3, 5]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"max_features\": [\"auto\", \"sqrt\"]\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear'),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": randint(3, 10),\n",
    "            \"learning_rate\": uniform(0.01, 0.2),\n",
    "            \"subsample\": uniform(0.6, 0.4),\n",
    "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
    "            \"gamma\": uniform(0, 0.5)\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"subsample\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "best_params = {} \n",
    "\n",
    "for name, config in search_spaces.items():\n",
    "    print(f\"\\n ...\")\n",
    "    if config[\"method\"] == \"grid\":\n",
    "        searcher = GridSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        searcher = RandomizedSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_distributions=config[\"params\"],\n",
    "            n_iter=30,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    searcher.fit(X_train, y_train)\n",
    "    best_model = searcher.best_estimator_\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": searcher.best_params_,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "    best_params[name] = searcher.best_params_\n",
    "\n",
    "\n",
    "    print(f\"   best: {searcher.best_params_}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "save_dir = \"nfkb\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "results_df.to_csv(\"nfkb/model_best_params_auc.csv\", index=False,)\n",
    "\n",
    "print(\"\\n:\\n\")\n",
    "import pprint\n",
    "pprint.pprint(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05f2de4-3672-4aad-a76e-6e07553d3cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree  AUC: 0.82\n",
      "RandomForest  AUC: 0.93\n",
      "LogisticRegression  AUC: 0.90\n",
      "XGBoost  AUC: 0.92\n",
      "GradientBoosting  AUC: 0.92\n"
     ]
    }
   ],
   "source": [
    "label = merged_df.iloc[:, 4]\n",
    "features = merged_df.iloc[:, 6:]\n",
    "binary_classes = sorted(label.unique())\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, stratify=label, random_state=42)\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42).set_params(**best_params[\"DecisionTree\"]),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42).set_params(**best_params[\"RandomForest\"]),\n",
    "    'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=200, random_state=42).set_params(**best_params[\"LogisticRegression\"]),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False, eval_metric='logloss').set_params(**best_params[\"XGBoost\"]),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42).set_params(**best_params[\"GradientBoosting\"])\n",
    "}\n",
    "results = []\n",
    "plt.figure(figsize=(10, 8))\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=binary_classes, yticklabels=binary_classes)\n",
    "    plt.title(f'{model_name} 混淆矩阵')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.svg', format='svg')\n",
    "    plt.close()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', lw=2)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc = evaluate_model(model, model_name)\n",
    "    print(f\"{model_name}  AUC: {auc:.2f}\")\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', lw=1)\n",
    "plt.title('ROC曲线', fontsize=16)\n",
    "plt.xlabel('假阳性率', fontsize=12)\n",
    "plt.ylabel('真阳性率', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.savefig('nfkb/combined_roc_curves.svg', format='svg')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('nfkb/model_evaluation_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935854b2-6216-46b2-9be2-ed0e1947d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = morgan_df2.iloc[:, 1:]\n",
    "rf_model = models[\"RandomForest\"] \n",
    "pred_labels = rf_model.predict(new_features)\n",
    "pred_probs = rf_model.predict_proba(new_features)[:, 1]\n",
    "\n",
    "df2[\"Predicted_Label\"] = pred_labels\n",
    "df2[\"Predicted_Probability\"] = pred_probs\n",
    "df2.to_csv(\"nfkb/prediction_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
